{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6935d0-4b6a-49cc-be74-7424aca6efce",
   "metadata": {},
   "source": [
    "Visual Crowd Preview Pipeline: Source localization on an Atlas with Beamformer\n",
    "==============================================================================\n",
    "\n",
    "Authors: Tasneem Ezzedine (te2207@nyu.edu), Hadi Zaatiti (hz3752@nyu.edu) and Osama Abdullah (oa22@nyu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf7528-8f38-4ae4-9cc6-b0fad94ae530",
   "metadata": {},
   "source": [
    "Experiment description\n",
    "----------------------\n",
    "\n",
    "[Link to experiment code](https://github.com/hzaatiti-NYU/meg-pipeline/blob/5ac461e002d1db916f57384f61e262060b9e2658/experiments/psychtoolbox/visual_crowding_preview)\n",
    "\n",
    "Contact for this experiment:\n",
    "\n",
    "Tasnim Ezzedin te2207@nyu.edu\n",
    "\n",
    "\n",
    "Description of the experiment:\n",
    "\n",
    "This experiment examines the crowding (the spacing between the letters within each word) and preview effects in the Arabic language, utilizing three distinct crowding values: 0, -75, and -125. Within the experiment, some values are attributed to the crowding effect as a label, respectively: 1 for -125, 2 for -75, and 3 for 0. These values are used in the naming of the images as well as in the final output of the .mat file. Within the .mat file, a column appears containing the number corresponding to the level of crowding (1, 2, or 3).\n",
    "For example, SET1_conn_0_cwdg_1_1.jpg, SET1_conn_0_cwdg_2_1.jpg, etc.\n",
    "Due to the nature of the arabic language being written in cursive, it has a varity of connections between letters. In the naming of the images, the 'conn' refers to the connectivity of the letters. For example, if a word has only two letters that are connected and a crowding level of 1 (i.e. -125) the name would be SET1_conn_2_cwdg_1_1.jpg.\n",
    "The stimuli are made of 300 different arabic words. SET1 has a different combination of crowding values assigned to the words than SET2, however, both have the same words.\n",
    "\n",
    "In this paradigm, participants are instructed to focus on a fixation point on the screen. Words will be presented either to the left or right of the fixation point, and participants will be required to look at the presented word when cued by the fixation point turning green. When a saccade is detected, the target word is displayed. \n",
    "The stimuli were presented as either valid or invalid, with the invalid stimulus being a flipped version of the valid one.\n",
    "After that, the participant has to decide weather or not the word displayed is the same your they saw during the trial by answering the question 'Is this the last word you saw?'.\n",
    "The study employs magnetoencephalography (MEG) and eye-tracking techniques to record brain activity.\n",
    "\n",
    "The trigger channels in MEG are as follows: \n",
    "\n",
    "- trigger channel 224: beginn of the overall experiment.\n",
    "- trigger channel 225: each display of the fixation point.\n",
    "- trigger channel 226: display of the preview image.\n",
    "- trigger channel 227: display of the cue (fixation point turns green).\n",
    "- trigger channel 228: saccade detection.\n",
    "- trigger channel 229: display of the target image.\n",
    "- trigger channel 230: display of the question image. \n",
    "\n",
    "Each trigger appears only once in each trial, except trigger channel 225, which appears each time the fixation point is presented. For example, if a fixation is not detected, channels 225 is triggered again until a fixation is detected. \n",
    "Triggers 227, 228, 229 should appear almost at the same time.\n",
    "\n",
    "The .mat file outputs a table with relevant information about the trials, such as the crowding level of each word that was displayed, weather or not it was valid or invalid, number of connections of the letters, question answers, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab8f39-066c-44ce-ada9-82452d5a2ffb",
   "metadata": {},
   "source": [
    "Importing data and preprocessing\n",
    "--------------------------------\n",
    "\n",
    "The data used in this notebook is hosted on `NYU BOX`. Permissions are given upon request.\n",
    "\n",
    "- Install the BOX app from [here](https://www.box.com/resources/downloads)\n",
    "- Set an environment variable with name `MEG_DATA` to the path of the Data folder e.g.,\n",
    "    - `C:\\Users\\user_name\\Box\\MEG\\Data`\n",
    "    - or `C:\\Users\\user_name\\Box\\Data`\n",
    "\n",
    "Each experiment run using the KIT system generates a `.con` and several `.mrk`. Find more details about these files in the other chapters.\n",
    "In the following setup the variables pointing to your data, headshape and MRI scan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877168d9-66cc-4068-9390-0539d4a38c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Read the environment variable to NYU BOX\n",
    "MEG_DATA_FOLDER = getenv('MEG_DATA');\n",
    "\n",
    "% Set path to KIT .con file of sub-03\n",
    "DATASET_PATH = [MEG_DATA_FOLDER,'visual_crowding_preview'];\n",
    "\n",
    "MEGFILES = dir(fullfile(DATASET_PATH, 'sub-*-vcp','meg-kit', 'sub-*-vcp-analysis_NR.con'));\n",
    "\n",
    "% Set path to computed .mat variables, these has been obtained by executing this pipeline and \n",
    "% will allow you to skip steps if you wish to execute a particular cell\n",
    "%LOAD_PATH = [MEG_DATA_FOLDER, 'oddball\\derivatives\\kit_oddball_pipeline_fieldtrip\\sub-03\\'];\n",
    "\n",
    "% Experiment your own test and save your variables in a folder of your choice, choose the folder where to save your variables\n",
    "% We will also use it to copy variables from LOAD_PATH and use them in the notebook if needed\n",
    "SAVE_PATH = 'docs\\source\\5-pipeline\\notebooks\\fieldtrip\\fieldtrip_visual_crowding_preview_kit_data\\';\n",
    "\n",
    "% It is important that you use T1.mgz instead of orig.mgz as T1.mgz is normalized to [255,255,255] dimension\n",
    "%MRI_FILE         = fullfile([MEG_DATA_FOLDER,'oddball\\sub-03\\anat\\sub-003\\sub-003\\mri\\T1.mgz']);\n",
    " \n",
    "%laser_surf      = fullfile([MEG_DATA_FOLDER,'oddball\\sub-03\\anat\\digitized-headshape\\sub-03-basic-surface.txt']);\n",
    "%The cleaned stylus points removes the last three columns (dx, dx, dz) and\n",
    "%keeps only x,y,z\n",
    "%laser_points    = [MEG_DATA_FOLDER, 'oddball\\sub-03\\anat\\digitized-headshape\\sub-03-stylus-cleaned.txt'];\n",
    "%mrkfile1        = [MEG_DATA_FOLDER,'oddball\\sub-03\\meg-kit\\240524-1.mrk'];\n",
    "%mrkfile2        = [MEG_DATA_FOLDER, 'oddball\\sub-03\\meg-kit\\240524-2.mrk'];\n",
    "\n",
    "try\n",
    "    cd(SAVE_PATH)\n",
    "catch\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5d871-2765-4c6f-80a8-850431c68f83",
   "metadata": {},
   "source": [
    "Loop over multi-subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a0b44-4524-48f2-ba3d-dbf5897c343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k = 1:length(MEGFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd5e26-c60f-430a-b7d9-d84d6114ff88",
   "metadata": {},
   "source": [
    "Trial definition and computing ERP in sensor space\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3fa6e-0784-4dd5-8552-a2dbb436525b",
   "metadata": {},
   "source": [
    "Using an Atlas headmodel for Beamformer\n",
    "---------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
